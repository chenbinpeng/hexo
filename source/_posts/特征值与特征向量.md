---
title: 特征值与特征向量
date: 2017-02-05 13:18:35
tags: 线性代数
categories: 数学
---



学线性代数，绕不过特征值与特征向量。它们的用途非常广，比如求矩阵的高次幂，解微分方程等。但想弄明白这两个概念却不容易。自己也一直困扰了很久。这两天在看用特征值和特征向量解微分方程，重新审视了一下这两个概念。略有所得，记录一下。



<!--more-->



##### 特征值与特征向量

我们知道，对于一个$n\times{n}$的非奇异矩阵$A$，当其作用于一个向量$x$时，相当于进行了一次线性变换。理论依据是，既然是非奇异矩阵，也就意味着矩阵$A$的各列线性无关。对于$n$个$n$维线性无关的列向量，通过线性组合可以张成一个$n\times{n}$的空间。而矩阵乘以一个向量，就相当于一个线性组合，如下：


$$
x'=Ax=\begin{bmatrix}a_1&a_2&\cdots&a_n\\ \end{bmatrix}\begin{bmatrix}x_1\\x_2\\\vdots\\x_n\\ \end{bmatrix}=a_1x_1+a_2x_2+\cdots+a_nx_n
$$
所以，向量$x$通过矩阵$A$被变换到了$x'$。矩阵$A$可以被看成一个线性变换算子。$n\times{n}$空间中的大多数向量通$A$以后都变的面目全非，不但被拉伸或缩短，还被进行了旋转，连方向都发生了改变。但还有少数向量方向不变，仅仅是长度发生了变化。如下图中绿色和粉色向量：

![Eigenvectors](Eigenvectors.gif)



对于在矩阵$A$的作用下，方向不变，只长度发生改变的向量$x$，称为矩阵$A$的特征向量。用公式表示为：
$$
Ax=\lambda{x}
$$
其中$\lambda$为缩放因子，也称为矩阵$A$的特征值。



不同的矩阵，其特征值和特征向量通常也不同。所以，特征值和特征向量在一定程度上反映了矩阵的某种特性，这也是为什么特征值和特征向量为什么含有“特征”二字的原因。



对于$n\times{n}$的非奇异矩阵$A$，通常也会有$n$个特征值和$n$个特征向量。并且$n$个特征向量线性无关，跟矩阵$A$的列向量一样，可以张成$n\times{n}$的空间。



既然特征向量在$A$的作用下发生伸缩变化，并且可以张成$n$维空间，为什么不选定特征向量作为一组基？这样$n$维空间中的向量都可以通过特征向量的线性组合来进行表示。矩阵作用于的任何一个向量都只是进行了伸缩，无疑会大大简化计算。



##### 在微分方程中的应用

比如，对于一个线性微分方程，
$$
\frac{d\mathbf{u}}{dt}=A\mathbf{u}=\begin{bmatrix}0&1\\1&0\\ \end{bmatrix}\mathbf{u}
$$
矩阵$A$的特征值和特征向量分别为$1$、$-1$，$(1,1)$、$(1,-1)$。可以被分解为：
$$
A=S\Lambda{S^{-1}}
$$
设特征向量$S$为基下的$\mathbf{u}$为：
$$
\mathbf{u}=S\mathbf{v}
$$
方程变为：
$$
\frac{d(S\mathbf{v})}{dt}=(S\Lambda{S^{-1}})(S\mathbf{v})
$$
化简后得：
$$
\frac{d\mathbf{v}}{dt}=\Lambda\mathbf{v}
$$
可以很方便的求出$\mathbf{v}$，然后通过$\mathbf{u}=S\mathbf{v}$得出最终结果。





##### 参考

[Eigenvalues and eigenvectors](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#History)

[Introduction to Linear Algebra(Gilbert Strang)](https://www.amazon.cn/gp/product/0980232716/ref=as_li_tf_tl?ie=UTF8&camp=536&creative=3200&creativeASIN=0980232716&linkCode=as2&tag=cbp00-23)

